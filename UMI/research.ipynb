{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
                "<hr>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# QuantBook Analysis Tool \n",
                "# For more information see [https://www.quantconnect.com/docs/v2/our-platform/research/getting-started]\n",
                "qb = QuantBook()\n",
                "spy = qb.add_equity(\"SPY\")\n",
                "# Locally Lean installs free sample data, to download more data please visit https://www.quantconnect.com/docs/v2/lean-cli/datasets/downloading-data \n",
                "qb.set_start_date(2013, 10, 11)\n",
                "history = qb.history(qb.securities.keys(), 360, Resolution.DAILY)\n",
                "\n",
                "# Indicator Analysis\n",
                "bbdf = qb.indicator(BollingerBands(30, 2), spy.symbol, 360, Resolution.DAILY)\n",
                "bbdf.drop('standarddeviation', axis=1).plot()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TRAINING VISUALS"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "project/\n",
                "└── UMI/\n",
                "    ├── main.py                  # (patched)\n",
                "    ├── modules.py               # contains StockLevelFactorLearning, …\n",
                "    ├── quick_view.ipynb         # Jupyter notebook\n",
                "    ├── data/                    # raw OHLCV csv files\n",
                "    │   ├── AAPL.csv\n",
                "    │   └── …\n",
                "    └── models/                  # ← will be auto-created on first run\n",
                "        └── UMI/\n",
                "            └── 1d/2025-06-22T14-30-24/\n",
                "                ├── bt_pred_close.csv\n",
                "                ├── bt_truth_close.csv\n",
                "                └── …"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import json, torch, pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd, matplotlib.pyplot as plt\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# find the newest run directory\n",
                "runs = sorted((Path(__file__).parent / \"models\" / \"UMI\" / \"1d\").iterdir(),\n",
                "              key=lambda p: p.stat().st_mtime)\n",
                "run_dir = runs[-1]\n",
                "\n",
                "MODEL_PATH = \"1d/2025-06-21T12-00-00\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model-properties overview  ────────────────────────────────────────────\n",
                "\n",
                "# ‣ point to the same run you loaded the loss curves from\n",
                "model_dir = Path(f\"models/UMI/1d/{MODEL_PATH}\")\n",
                "state_file   = model_dir / \"best.pt\"\n",
                "hparams_file = model_dir / \"hparams.json\"\n",
                "param_inv_csv = model_dir / \"param_inventory.csv\"       \n",
                "hp_trials_csv = model_dir / \"hp_trials.csv\"             \n",
                "\n",
                "# ── A. hyper-parameter dictionary ─────────────────────────────────────────\n",
                "with hparams_file.open() as fp:\n",
                "    hparams = json.load(fp)\n",
                "\n",
                "hp_df = pd.DataFrame(hparams.items(), columns=[\"param\", \"value\"])\n",
                "display(hp_df.style.set_caption(\"Saved hyper-parameters\"))\n",
                "\n",
                "# ── B. parameter inventory  (counts + memory) ────────────────────────────\n",
                "state = torch.load(state_file, map_location=\"cpu\")\n",
                "\n",
                "records, total_params, total_bytes = [], 0, 0\n",
                "for top_key, block in state.items():                 # e.g. 'stock_factor', …\n",
                "    if isinstance(block, dict):                      # sub-module dict\n",
                "        for name, tensor in block.items():\n",
                "            full_name = f\"{top_key}.{name}\"\n",
                "            n = tensor.numel()\n",
                "            b = n * tensor.element_size()\n",
                "            records.append((full_name, list(tensor.shape), n, b))\n",
                "            total_params += n\n",
                "            total_bytes  += b\n",
                "    else:                                            # flat tensor\n",
                "        n = block.numel()\n",
                "        b = n * block.element_size()\n",
                "        records.append((top_key, list(block.shape), n, b))\n",
                "        total_params += n\n",
                "        total_bytes  += b\n",
                "\n",
                "param_df = pd.read_csv(param_inv_csv)\n",
                "\n",
                "# pretty display – show the 20 largest tensors first\n",
                "display(param_df.head(20).style.set_caption(\"Largest tensors (by #params)\"))\n",
                "\n",
                "print(f\"Total learnable parameters : {total_params:,}\")\n",
                "print(f\"≈ Model size (fp32)        : {total_bytes/1024/1024:.1f} MB\")\n",
                "\n",
                "# ── C. optional: visual snapshot of the heaviest tensors ──────────────────\n",
                "top = param_df.head(10)           # top-10 by param count\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.bar(top[\"tensor\"], top[\"numel\"])\n",
                "plt.ylabel(\"# parameters\")\n",
                "plt.title(\"Top-10 tensors by parameter count\")\n",
                "plt.xticks(rotation=45, ha=\"right\")\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "pred  = pd.read_csv(run_dir / \"bt_pred_close.csv\",  index_col=0, parse_dates=True)\n",
                "truth = pd.read_csv(run_dir / \"bt_truth_close.csv\", index_col=0, parse_dates=True)\n",
                "\n",
                "ticker = \"AAPL\"\n",
                "\n",
                "fig, ax = plt.subplots()\n",
                "ax.plot(truth.index, truth[ticker], label=\"real close\")\n",
                "ax.plot(pred.index,  pred[ticker],  label=\"predicted close\")\n",
                "ax.set_title(f\"{ticker} – 1-bar-ahead close forecast\")\n",
                "ax.legend()\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
