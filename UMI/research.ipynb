{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
                "<hr>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# QuantBook Analysis Tool \n",
                "# For more information see [https://www.quantconnect.com/docs/v2/our-platform/research/getting-started]\n",
                "qb = QuantBook()\n",
                "spy = qb.add_equity(\"SPY\")\n",
                "# Locally Lean installs free sample data, to download more data please visit https://www.quantconnect.com/docs/v2/lean-cli/datasets/downloading-data \n",
                "qb.set_start_date(2013, 10, 11)\n",
                "history = qb.history(qb.securities.keys(), 360, Resolution.DAILY)\n",
                "\n",
                "# Indicator Analysis\n",
                "bbdf = qb.indicator(BollingerBands(30, 2), spy.symbol, 360, Resolution.DAILY)\n",
                "bbdf.drop('standarddeviation', axis=1).plot()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TRAINING VISUALS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3️⃣ Model-properties overview  ────────────────────────────────────────────\n",
                "from pathlib import Path\n",
                "import json, torch, pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ‣ point to the same run you loaded the loss curves from\n",
                "model_dir = Path(\"../models/UMI/1d/2025-06-21T12-00-00\")\n",
                "state_file   = model_dir / \"best.pt\"\n",
                "hparams_file = model_dir / \"hparams.json\"\n",
                "param_inv_csv = model_dir / \"param_inventory.csv\"       \n",
                "hp_trials_csv = model_dir / \"hp_trials.csv\"             \n",
                "\n",
                "# ── A. hyper-parameter dictionary ─────────────────────────────────────────\n",
                "with hparams_file.open() as fp:\n",
                "    hparams = json.load(fp)\n",
                "\n",
                "hp_df = pd.DataFrame(hparams.items(), columns=[\"param\", \"value\"])\n",
                "display(hp_df.style.set_caption(\"Saved hyper-parameters\"))\n",
                "\n",
                "# ── B. parameter inventory  (counts + memory) ────────────────────────────\n",
                "state = torch.load(state_file, map_location=\"cpu\")\n",
                "\n",
                "records, total_params, total_bytes = [], 0, 0\n",
                "for top_key, block in state.items():                 # e.g. 'stock_factor', …\n",
                "    if isinstance(block, dict):                      # sub-module dict\n",
                "        for name, tensor in block.items():\n",
                "            full_name = f\"{top_key}.{name}\"\n",
                "            n = tensor.numel()\n",
                "            b = n * tensor.element_size()\n",
                "            records.append((full_name, list(tensor.shape), n, b))\n",
                "            total_params += n\n",
                "            total_bytes  += b\n",
                "    else:                                            # flat tensor\n",
                "        n = block.numel()\n",
                "        b = n * block.element_size()\n",
                "        records.append((top_key, list(block.shape), n, b))\n",
                "        total_params += n\n",
                "        total_bytes  += b\n",
                "\n",
                "param_df = pd.read_csv(param_inv_csv)\n",
                "\n",
                "# pretty display – show the 20 largest tensors first\n",
                "display(param_df.head(20).style.set_caption(\"Largest tensors (by #params)\"))\n",
                "\n",
                "print(f\"Total learnable parameters : {total_params:,}\")\n",
                "print(f\"≈ Model size (fp32)        : {total_bytes/1024/1024:.1f} MB\")\n",
                "\n",
                "# ── C. optional: visual snapshot of the heaviest tensors ──────────────────\n",
                "top = param_df.head(10)           # top-10 by param count\n",
                "plt.figure(figsize=(12, 4))\n",
                "plt.bar(top[\"tensor\"], top[\"numel\"])\n",
                "plt.ylabel(\"# parameters\")\n",
                "plt.title(\"Top-10 tensors by parameter count\")\n",
                "plt.xticks(rotation=45, ha=\"right\")\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
